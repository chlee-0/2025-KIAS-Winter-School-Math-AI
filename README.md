# 2025 KIAS Winter School on Mathematics and AI

**Temporary information page; official website coming soon.**

### TL;DR
- Dates: December 2–5, 2025
- Venue: Park Roche, Jeongseon — <https://park-roche.com/>
- Apply Now: <https://forms.gle/oaApy67SgbAsRrYMA> (Google Form; application deadline: Nov 13, 18:00 KST)

[Home](#home) | [Program](#program) | [Timetable](#timetable) | [Venue](#venue) | [Registration](#registration)

---

## Home

The 2025 KIAS Winter School on Mathematics and AI is a four‑day hackathon‑style program at the intersection of mathematics and AI. Teams work in parallel on hands‑on projects in math‑for‑AI, AI‑for‑math, and formalization. The program also includes invited talks on related topics.

### Topics & Keywords (tentative)

- Formalization (Lean), Autoformalization, Informalization
- Machine Learning for Mathematics
- Large Language Models
- Reinforcement Learning

### Organizers

- Joonhyun La (KIAS)
- Chul‑hee Lee (KIAS)
- Kyu‑Hwan Lee (University of Connecticut / KIAS)

### Team Leads (tentative)

- Ilkyoo Choi (HUFS / DIMAG, IBS)
- Byung-Hak Hwang (KIAS)
- Jihoon Hyun (KAIST)
- Chul‑hee Lee (KIAS)
- Seewoo Lee (UC Berkeley)
- Hyojae Lim (RICAM)


### Speakers

- Dohyun Kwon (University of Seoul)
- Kyu‑Hwan Lee (University of Connecticut / KIAS)
- Hongseok Yang (KAIST)


### Contact

- Email: chlee@kias.re.kr (Chul‑hee Lee)

### Supported by

- Korea Institute for Advanced Study (KIAS), HCMC

---

## Program

### Talks
 - Speaker: Dohyun Kwon (University of Seoul)
 - Title: Generative Modeling Through the Lens of Optimal Transport
 - Abstract: Generative models have achieved remarkable success across a wide range of machine learning tasks. This talk presents a unified perspective on generative modeling through the lens of optimal transport, viewing learning as an optimization problem over the space of probability measures. We will explore how this framework inspires connections between diffusion models, energy-based models, and GANs. Along the way, we will highlight recent advances and discuss how these ideas extend new directions for advancing generative models.

⋯

 - Speaker: Kyu‑Hwan Lee (University of Connecticut / KIAS)
 - Title: TBA
 - Abstract: TBA

⋯ 

 - Speaker: Hongseok Yang (KAIST)
 - Title: Tackling asymptotic extremal problems in graph theory using neural networks
 - Abstract: Assisting mathematical discovery with machine learning techniques has been an active research topic in the machine-learning community in recent years, yielding impressive results such as the discovery of key insights into or counterexamples for open conjectures in knot theory, representation theory, arithmetic geometry and combinatorics. In this talk, I will describe our ongoing efforts for extending this line of research to extremal combinatorics. We consider the asymptotic extremal problems on graphs, which are just a particular type of optimisation problems on an infinite limiting version of graphs, called graphons. We aim at helping prove or disprove open conjectures for such problems using tools from machine learning. Our idea is to represent these infinite limiting graphs using carefully-designed neural networks, and to solve these optimisation problems using gradient descent. I will describe what challenges we encountered, how we overcame those challenges by designing a particular architecture for neural networks inspired by the popular diffusion model, and what new insights into the well-known asymptotic extremal problems we gained by our approach. This is joint work with Taeyoung Kim from KAIST, Jineon Baek from KIAS, and Joonkyung Lee from Yonsei University.

### Team Programs
- Participants will be grouped into teams; the application page currently lists only the titles of team project topics, and more detailed information will be provided later: <https://forms.gle/oaApy67SgbAsRrYMA>.

#### Team 1
  - Team Leads: Byung-Hak Hwang (KIAS), Ilkyoo Choi (HUFS / DIMAG, IBS)
  - Title: ML and Discrete Mathematics
  - Abstract: Our team will explore FunSearch! We aim to understand (1) how FunSearch works, (2) what kinds of mathematics FunSearch can handle, (3) how to use FunSearch in practice, and then (4) we will apply FunSearch to some combinatorial problems. No specific background is required, but familiarity with combinatorics, machine learning, or programming in Python will be helpful.

#### Team 2
  - Team Lead: Hyojae Lim (RICAM)
  - Title: Autoformalization
  - Abstract: This project explores autoformalization, the automatic translation of natural-language mathematical definitions into formal definitions in Lean. We focus on how large language models (LLMs) can be guided to produce Lean definitions based on the rules for defining data types, particularly inductive types. During the project, we will study how mathematical concepts and definitions can be represented in Lean, experiment with LLM-based translation pipelines, and analyze the interpretability and stability of the resulting formalizations. Participants will gain hands-on experience with Lean and LLM prompting; prior familiarity with Lean or Python programming will be helpful but not required.

#### Team 3
  - Team Lead: Seewoo Lee (UC Berkeley)
  - Title: ML and Number Theory
  - Abstract: The main goal of our group is to use (classical/modern) ML algorithms to predict number-theoretic invariants. Before the winter school, we are going to learn basic ML algorithms and how they can be used to solve easy problems in number theory. Then we will consider more advanced topics, including Artin representations and abelian varieties over finite fields, aiming for discovering new phenomena. We assume that members are familiar with graduate-level number theory but not assuming any background on machine learning.

#### Team 4
  - Team Lead: Chul‑hee Lee (KIAS)
  - Title: Reinforcement Learning and Canonical Forms in Mathematics
  - Abstract: This project explores how reinforcement learning (RL) can be applied to the process of reducing mathematical objects to their canonical forms. RL is a framework in which an agent learns to take sequential actions through interaction with an environment, guided by rewards and feedback. From this viewpoint, it seems plausible to explore step-by-step procedures such as Gaussian elimination through the lens of RL. During the preparatory phase, participants will study the fundamentals of RL and gain hands-on experience in simple environments using tools such as Gymnasium. We then treat various standardization processes as agent-driven search problems, examining how RL can replicate or extend traditional algorithmic methods. Background in Python programming and undergraduate-level abstract algebra will be helpful.

#### Team 6
  - Team Lead: Jihoon Hyun (KAIST)
  - Title: Formalization
  - Abstract: TBA

---

## Timetable

High‑level schedule; detailed times TBA.

### Day 1 (Tue): Arrival & Kickoff
- Arrival/registration/lunch; opening + team kickoff; evening hacking.

### Day 2 (Wed): 
- Talk 1; Team hacking.

### Day 3 (Thu): 
- Talk 2; Team hacking; Team presentations; banquet and networking.

### Day 4 (Fri): Closing & Departure
- Talk 3; lunch; departure.


---

 
## Venue

- **Park Roche**, Jeongseon — <https://park-roche.com/>

### Transportation

- **Shuttle Bus (tentative)**
  - A shuttle bus will be arranged between **KIAS** and **Park Roche** for participants.  
  - **KIAS → Park Roche:** Dec 2 (Tue) 9:00 AM (approx. 3 h 30 min)  
  - **Park Roche → KIAS:** Dec 5 (Fri) 1:30 PM (approx. 3 h 30 min)  
  - *Times are subject to change.*



## Registration

Apply Now: <https://forms.gle/oaApy67SgbAsRrYMA> (Google Form; application deadline: Nov 13, 18:00 KST)
